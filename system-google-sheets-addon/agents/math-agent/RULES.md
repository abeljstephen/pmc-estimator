# Mathematical Quality Assurance Rules for PMC Estimator

## Core Mathematical Constraints

### 1. Beta Distribution Validity
**Purpose**: Ensure Beta distribution parameterization is mathematically sound

- **Parameters**: α > 0, β > 0 (must both be strictly positive)
- **Location**: Check `core/baseline/beta-points.gs` and any moment-fitting code
- **Implementation Check**:
  - All Beta parameters must be computed from α, β > 0
  - Check that `fitBetaToPert()` doesn't produce invalid parameters
  - Verify bounds: distribution is properly scaled to [O, P]
- **Edge Cases**:
  - When O = M = P (degenerate case): Should handle gracefully
  - When O ≈ M ≈ P: Verify variance doesn't collapse to exact skewness
  - Boundary values: Distribution shouldn't exceed [O, P] bounds

### 2. Gaussian Copula Mathematical Soundness
**Purpose**: Ensure dependency modeling between sliders is valid

- **Correlation Matrix**: `BASE_R` (7×7) must be positive semi-definite (PSD)
  - All eigenvalues λ ≥ 0
  - Determinant ≥ 0
  - Condition number shouldn't be pathological (< 100 typically OK)
- **Correlation Values**: All entries ∈ [-1, 1]
- **Location**: `core/reshaping/copula-utils.gs`
- **Integration**: Used by `slider-adjustments.gs` and `optimizer.gs`
- **Check**:
  - Is BASE_R documented with source (PMBOK reference)?
  - Are correlations empirically justified?
  - What happens if two sliders are perfectly correlated?

### 3. KL Divergence Mathematical Properties
**Purpose**: Measure distribution distortion correctly

- **Definition**: KL(Q || P) = ∫ Q(x) log(Q(x)/P(x)) dx
- **Properties that MUST hold**:
  - KL(Q || P) ≥ 0 (always non-negative)
  - KL(Q || P) = 0 ⟺ Q = P almost everywhere
  - KL is NOT symmetric: KL(Q || P) ≠ KL(P || Q)
- **Location**: `core/optimization/kl-divergence.gs`
- **Implementation Checks**:
  - No log(0) or division by zero
  - Numerical integration handles PDF tails properly
  - Verify asymmetry: KL(baseline || reshaped) vs KL(reshaped || baseline)
- **Usage**:
  - Threshold: maxDiv = 0.08 (safety valve in optimizer)
  - Reversion logic: If KL > 0.08, should revert to baseline
- **Edge Cases**:
  - What if Q and P have non-overlapping support?
  - What if one distribution has zero density where other is nonzero?

### 4. Moment Mapping & Preservation
**Purpose**: Ensure statistical moments stay valid during reshaping

- **Constraints**:
  - Original mean μ₀ must be in [O, P]
  - Variance σ² must satisfy: 0 ≤ σ² ≤ (P - O)²/12
  - The maximum variance occurs when distribution is uniform over [O, P]
- **Moment Computation**:
  - m₀ (mean): Must be within [O, P]
  - m₁ (variance): Must be non-negative and ≤ max possible variance
  - Higher moments: Check for numerical stability
- **Location**: `core/reshaping/slider-adjustments.gs` and `copula-utils.gs`
- **Check**:
  - After each reshape: Verify new moments satisfy constraints
  - After optimization: Ensure moments didn't violate bounds
  - Integration: Reshaped Beta fit should preserve moments accurately

### 5. CDF/PDF Point Set Validity
**Purpose**: Ensure probability functions are mathematically valid

- **CDF Requirements**:
  - Monotone increasing: CDF[i] ≤ CDF[i+1] for all i
  - Boundary conditions: CDF[0] ≈ 0, CDF[n-1] ≈ 1
  - Range: All values ∈ [0, 1]
  - Smoothness: Should not have jumps or kinks (except boundary)
- **PDF Requirements**:
  - Non-negative: PDF[i] ≥ 0 for all i
  - Integrates to ~1.0 (within ±0.01)
  - Smooth: Shouldn't have sharp spikes unless mathematically justified
- **Location**: Generated by `core/baseline/*-points.gs` files
- **Validation Function**: `core/helpers/validation.gs`
- **Checks**:
  - After baseline generation: Verify CDF is monotone, integrates correctly
  - After reshape: Verify new PDF/CDF are valid
  - After optimization: Check all point arrays match their CDF/PDF definitions

### 6. PERT Formula Implementation
**Purpose**: Ensure PERT mean/variance computed correctly

- **PERT Mean**: μ_PERT = (O + 4M + P) / 6
- **PERT Variance**: σ²_PERT = ((P - O) / 6)²
- **Beta Parameterization**: From μ and σ², derive α and β:
  - Mean = O + (P - O) × [α / (α + β)]
  - Variance = (P - O)² × [αβ / ((α + β)²(α + β + 1))]
- **Location**: `core/baseline/pert-points.gs`
- **Check**:
  - Does fitted Beta match PERT mean and variance?
  - Are Beta parameters computed correctly?
  - Does this integrate with `generateBaseline()` correctly?

### 7. KDE Smoothing Numerical Stability
**Purpose**: Ensure Kernel Density Estimation doesn't introduce artifacts

- **Bandwidth Calculation**: h = range / 63.3 (rule-of-thumb)
- **Gaussian Kernel**: K(z) = exp(-0.5z²) / √(2π)
- **Location**: `core/baseline/monte-carlo-smoothed.gs`
- **Checks**:
  - Bandwidth h > 0 and is reasonable (not too small/large)
  - Kernel integration is numerically stable
  - Smoothing doesn't create spurious probability mass outside [O, P]
  - Edge effects: How does KDE handle boundaries?

### 8. Trapezoid Integration Numerical Accuracy
**Purpose**: Numerical integration must be accurate enough for metrics

- **Method**: Trapezoidal rule for ∫ f(x) dx
- **Location**: `core/helpers/metrics.gs` - `trapezoidIntegral()`
- **Accuracy Concerns**:
  - Point spacing: Are x-values evenly spaced? (affects accuracy)
  - Tail behavior: How does it handle PDF tails?
  - Cumulative error: Over many integrations, error accumulates
- **Check**:
  - CDF at final point should be ≈ 1.0 (not 0.98 or 1.02)
  - Compare trapezoidal vs. Simpson's rule for critical functions
  - Test with known analytical integrals (e.g., normal, uniform)

### 9. Latin Hypercube Sampling
**Purpose**: Optimizer exploration should be efficient and unbiased

- **Properties**:
  - Each dimension divided into N equal-probability strata
  - One sample per stratum (improves coverage vs. random)
  - No correlation between dimensions (independent sampling)
- **Location**: `core/optimization/optimizer.gs`
- **Checks**:
  - Sample count matches probe level (depth ∝ samples)
  - Random permutation is truly random (seeded correctly)
  - Samples cover full slider space [0, 1]^7

### 10. Optimization Reversion Logic
**Purpose**: Ensure safety valve prevents invalid distributions

- **Trigger**: If KL(refit || baseline) > maxDiv (currently 0.08)
- **Action**: Revert to baseline sliders
- **Location**: `core/optimization/optimizer.gs`
- **Recalculation**: After revert, must recalculate probability at target
  - Old behavior: Might have stale probability values
  - Current requirement: Post-revert recalc to ensure "Points" = "% Confidence"
- **Checks**:
  - Does reversion actually prevent invalid distributions?
  - Is the recalculation performed?
  - Is maxDiv = 0.08 justified? (Is it too conservative/aggressive?)

---

## Integration Checks (Mathematical Cross-Component Validation)

### Baseline → Reshape Flow
1. Baseline PDF/CDF computed from Beta distribution
2. Reshape takes baseline CDF, applies copula mapping, re-fits Beta
3. **Check**: New Beta moments must satisfy: m₀ ∈ [O, P], m₁ ≤ max variance
4. **Check**: New PDF must integrate to 1.0
5. **Check**: KL divergence computed correctly

### Reshape → Optimization Flow
1. Reshape outputs validated PDF/CDF and probability
2. Optimizer uses SACO geometry to search slider space
3. **Check**: Optimizer respects moment constraints from reshape
4. **Check**: KL divergence threshold (maxDiv = 0.08) gates reversion
5. **Check**: Post-revert probability is recalculated

### Probability Chain
1. Baseline probability computed from baseline CDF at target
2. Adjusted probability computed from reshaped CDF at target
3. Optimized probability computed from optimized CDF at target
4. **Check**: Each probability is consistent with its CDF
5. **Check**: No probability exceeds 1.0 or drops below 0
6. **Check**: Probability at target ≤ CDF(target + ε) for any ε > 0

---

## Numerical Stability Red Flags

Watch for these in any mathematical operation:

- **Division by zero**: Check denominators before dividing
- **log(0) or log(negative)**: Check arguments before logging
- **Underflow/overflow**: Very large or very small numbers (< 1e-300, > 1e300)
- **Cancellation error**: Subtracting nearly-equal numbers
- **Accumulation error**: Many small rounding errors adding up
- **Boundary pathology**: Behavior near [O, P] limits, near zero probability

---

## Mathematical Improvements to Watch For

(See `IMPROVEMENTS.md` for specific advances to consider)

---

## Severity Levels

When flagging issues, use:
- **CRITICAL**: Wrong probability calculations, violated moment bounds, invalid distributions
- **HIGH**: Integration problems between components, KL divergence logic errors, CDF monotonicity broken
- **MEDIUM**: Numerical stability concerns, suboptimal integrations, suspicious parameter ranges
- **LOW**: Performance improvements, code clarity, documentation suggestions

---

## Last Updated
February 15, 2026

## References
- PMBOK (Project Management Body of Knowledge) - Correlation matrix basis
- Gaussian Copula literature - SACO geometry
- Beta Distribution properties - Wikipedia/textbooks
- Kullback-Leibler Divergence - Information theory standard
